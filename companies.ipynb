{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df6d39d7-63a9-4969-9a80-06c3408bbf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyalex import (\n",
    "    Works, Authors, Sources,\n",
    "    Institutions, Concepts, Publishers, Funders\n",
    ")\n",
    "import pyalex\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pyalex.config.email = \"david@rs21.io\"\n",
    "\n",
    "### ssl problems\n",
    "# https://support.chainstack.com/hc/en-us/articles/9117198436249-Common-SSL-Issues-on-Python-and-How-to-Fix-it\n",
    "\n",
    "from flair.embeddings import DocumentPoolEmbeddings\n",
    "from flair.data import Sentence\n",
    "from flair.embeddings import SentenceTransformerDocumentEmbeddings\n",
    "\n",
    "EMBEDDING_MODEL_1 = \"all-mpnet-base-v2\" \n",
    "\n",
    "# this one is also good: all-MiniLM-L6-v2\n",
    "EMBEDDING_MODEL_2 = \"all-MiniLM-L6-v2\"\n",
    "SENT_EMBEDDINGS_1 = SentenceTransformerDocumentEmbeddings(EMBEDDING_MODEL_1)\n",
    "SENT_EMBEDDINGS_2 = SentenceTransformerDocumentEmbeddings(EMBEDDING_MODEL_2)\n",
    "DOC_EMBEDDINGS= DocumentPoolEmbeddings([SENT_EMBEDDINGS_2])\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import yake\n",
    "import umap.umap_ as umap\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "import altair as alt\n",
    "import math\n",
    "import plotly.express as px\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf103272-770e-482f-b915-ec39429916c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_works_list(worklist:list):\n",
    "    \"\"\"\n",
    "    transforms the \n",
    "    works list into a dataframe.\n",
    "    \"\"\"\n",
    "    abstracts_dict = {h[\"id\"]:h[\"abstract\"] for h in worklist}\n",
    "    df = pd.DataFrame.from_records(worklist)\n",
    "    try: \n",
    "        del df['abstract_inverted_index'] # though don't all have abstracts is the problem\n",
    "        df['abstract'] = df['id'].map(abstracts_dict)\n",
    "    except:\n",
    "        pass\n",
    "   # df['author_affils'] = df['authorships'].apply(get_authors_and_affils)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ca597d3-d50b-4334-8030-39e67621c553",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyalex import config\n",
    "\n",
    "config.max_retries = 0\n",
    "config.retry_backoff_factor = 0.1\n",
    "config.retry_http_codes = [429, 500, 503]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e1ad01-6f9b-4b26-89f3-d52a33f5940e",
   "metadata": {},
   "source": [
    "https://github.com/J535D165/pyalex\n",
    "\n",
    "How to get all the works from US companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27760e5e-cdc4-4296-a00d-c529f2f48f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Works().random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62931672-434b-4982-a584-c26e5f321adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Works().filter(authorships={\"institutions\": {\"country_code\": \"US\",\n",
    "#                                             \"type\": \"company\"}}).get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28d2081a-c21f-4449-9054-8abd06fc91e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_country_type_frame(country_code:str, affil_type:str):\n",
    "    \"\"\"\n",
    "    takes a country_code and affil_type\n",
    "    and forms the pagination object to retrive the \n",
    "    records\n",
    "    \"\"\"\n",
    "    pager = Works().filter(publication_year = '>2021',\n",
    "        authorships={\"institutions\": {\"country_code\": country_code,\n",
    "                        \"type\": affil_type}}).paginate(\n",
    "        per_page=200, n_max=100_000)\n",
    "   # pager = Works().filter(publication_year='>2018',\n",
    "   # authorships={\"institutions\": {\"ror\": ror}}).paginate(\n",
    "   #     per_page=200, n_max=None)\n",
    "    #pager = Works().filter(publication_year='>2016',\n",
    "    #concepts={\"id\":f\"{concepts_list[i]['id']}\"}).filter(authorships={\"institutions\":{\"country_code\":\"CN\"}}).\\\n",
    "    #paginate(per_page=200,n_max=None)\n",
    "    #concepts={\"id\":f\"{concepts_list[i]['id']}\"}).\\\n",
    "    #paginate(per_page=200,n_max=None)\n",
    "    df = pd.DataFrame()\n",
    "    for page in tqdm(pager):\n",
    "        dfpage = process_works_list(page)\n",
    "        df = pd.concat([df, dfpage], ignore_index=True)\n",
    "        df.drop_duplicates(subset='id', keep='first',inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "939237b6-d354-4317-8a78-9e9309a242ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [23:05,  2.77s/it]\n"
     ]
    }
   ],
   "source": [
    "df = get_country_type_frame(country_code=\"US\", affil_type=\"company\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c857c0-8545-4f22-a667-ce8e709ee069",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
